{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP6pYoeoH7Z9q9tW3jgOfsc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E0XlszNFWpI3","executionInfo":{"status":"ok","timestamp":1761479425873,"user_tz":-60,"elapsed":27,"user":{"displayName":"Hernan Diaz Rodriguez","userId":"01995553725561234934"}},"outputId":"36cdb32f-f98a-45e2-dd73-489684b97a4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Política aprendida por Q-Learning:\n","> > v v \n","v > > v \n","v v > v \n","> > > ^ \n","--------------------\n","Valores Q máximos por casilla:\n"," 1.81  3.12  4.58  6.20 \n"," 3.12  4.57  6.20  8.00 \n"," 4.58  6.08  8.00 10.00 \n"," 6.20  8.00 10.00  0.00 \n","--------------------\n"]}],"source":["import numpy as np\n","\n","class GridWorldQLearning:\n","    def __init__(self, size=4, obstacles=None, start=(0,0), goal=(3,3)):\n","        self.size = size\n","        self.n_states = size * size\n","        self.n_actions = 4  # arriba, abajo, izquierda, derecha\n","\n","        self.start_state = start\n","        self.goal_state = goal\n","        self.obstacles = obstacles if obstacles else [(1,1),(2,2)]\n","\n","        # Acciones\n","        self.actions = {\n","            0: (-1, 0),  # arriba\n","            1: (1, 0),   # abajo\n","            2: (0, -1),  # izquierda\n","            3: (0, 1)    # derecha\n","        }\n","\n","    def _pos_to_state(self, pos):\n","        return pos[0] * self.size + pos[1]\n","\n","    def _state_to_pos(self, state):\n","        return (state // self.size, state % self.size)\n","\n","    def _is_valid_position(self, pos):\n","        return 0 <= pos[0] < self.size and 0 <= pos[1] < self.size\n","\n","    def step(self, state, action):\n","        \"\"\"Ejecuta la acción y devuelve next_state, reward, done\"\"\"\n","        pos = self._state_to_pos(state)\n","        move = self.actions[action]\n","        new_pos = (pos[0] + move[0], pos[1] + move[1])\n","\n","        if not self._is_valid_position(new_pos):\n","            new_pos = pos  # quedarse en el mismo lugar\n","\n","        reward = -1  # costo normal\n","        if new_pos in self.obstacles:\n","            reward = -5\n","        if new_pos == self.goal_state:\n","            reward = 10\n","\n","        done = new_pos == self.goal_state\n","        next_state = self._pos_to_state(new_pos)\n","        return next_state, reward, done\n","\n","    def q_learning(self, episodes=500, alpha=0.5, gamma=0.9, epsilon=0.1):\n","        Q = np.zeros((self.n_states, self.n_actions))\n","\n","        for ep in range(episodes):\n","            state = self._pos_to_state(self.start_state)\n","            done = False\n","\n","            while not done:\n","                # epsilon-greedy\n","                if np.random.rand() < epsilon:\n","                    action = np.random.randint(self.n_actions)\n","                else:\n","                    action = np.argmax(Q[state])\n","\n","                next_state, reward, done = self.step(state, action)\n","\n","                # Q-Learning update\n","                Q[state, action] = Q[state, action] + alpha * (\n","                    reward + gamma * np.max(Q[next_state]) - Q[state, action]\n","                )\n","\n","                state = next_state\n","\n","        # Extraer política final\n","        policy = np.argmax(Q, axis=1)\n","        return Q, policy\n","\n","    def print_policy_matrix(self, policy):\n","      arrow_symbols = ['^', 'v', '<', '>']\n","      for i in range(self.size):\n","          row_str = \"\"\n","          for j in range(self.size):\n","              state = self._pos_to_state((i,j))\n","              row_str += arrow_symbols[policy[state]] + \" \"\n","          print(row_str)\n","      print(\"-\"*20)\n","\n","    def print_q_max_matrix(self, Q):\n","        \"\"\"Imprime el valor máximo Q(s,a) de cada casilla en formato matriz\"\"\"\n","        Q_max = np.max(Q, axis=1).reshape(self.size, self.size)\n","        for i in range(self.size):\n","            row_str = \"\"\n","            for j in range(self.size):\n","              row_str += f\"{Q_max[i,j]:5.2f} \"\n","            print(row_str)\n","        print(\"-\"*20)\n","\n","grid = GridWorldQLearning()\n","Q, policy = grid.q_learning(episodes=1000, alpha=0.5, gamma=0.9, epsilon=0.1)\n","\n","print(\"Política aprendida por Q-Learning:\")\n","grid.print_policy_matrix(policy)\n","\n","print(\"Valores Q máximos por casilla:\")\n","grid.print_q_max_matrix(Q)"]}]}